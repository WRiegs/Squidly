{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0e4372-ef85-449b-8f32-ed976ccb1c44",
   "metadata": {},
   "source": [
    "# Run the models using the defaults which were selected in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c888e505-24c6-438b-9e8b-bb0c58f067a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m                      Number of AEGAN training set:\t9888\t                       \u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict\n",
    "from sciutil import SciUtil\n",
    "import seaborn as sns\n",
    "\n",
    "u = SciUtil()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "swissprot = pd.read_csv('../manuscript/data/reviewed_sprot_08042025.tsv', sep='\\t')\n",
    "data_dir = '/disk1/ariane/vscode/squidly/manuscript/AEGAN_extracted_sequences/'\n",
    "\n",
    "def compute_uncertainties(df, prob_columns, seq_col, mean_prob=0.5, mean_var=1):\n",
    "    means, variances, residues, entropy_values  = [], [], [], []\n",
    "    for p1, p2, p3, p4, p5, seq in tqdm(df[prob_columns + [seq_col]].values):\n",
    "        mean_values = []\n",
    "        variance_values = []\n",
    "        entropys = []\n",
    "        indicies = []\n",
    "        for j in range(0, len(seq)):\n",
    "            try:\n",
    "                if j > len(p1): # only go to 1024 - a limitation atm\n",
    "                    mean_probs = 0\n",
    "                    vars = 1 # Highlight these are incorrect\n",
    "                else:\n",
    "                    eps = 1e-8 # For non-zeros\n",
    "                    all_probs = [p1[j] + eps, p2[j] + eps, p3[j] + eps, p4[j] + eps, p5[j] + eps]\n",
    "                    mean_probs = np.mean(all_probs)\n",
    "                    entropy = -((mean_probs * np.log2(mean_probs)) + ((1 - mean_probs) * np.log2(1 - mean_probs)))\n",
    "                    vars = np.var(all_probs) # use variance as a proxy\n",
    "                    if mean_probs > mean_prob and vars < mean_var: # Use the supplied cutoffs\n",
    "                        indicies.append(j)\n",
    "                mean_values.append(mean_probs)\n",
    "                variance_values.append(vars)\n",
    "                entropys.append(entropy)\n",
    "            except:\n",
    "                mean_values.append(0)\n",
    "                variance_values.append(1)\n",
    "                entropys.append(1)\n",
    "        means.append(mean_values)\n",
    "        variances.append(variance_values)\n",
    "        entropy_values.append(entropys)\n",
    "        residues.append('|'.join([str(s) for s in indicies]))\n",
    "    return means, entropy_values, variances, residues\n",
    "\n",
    "\n",
    "def calculate_stats(df, id_col, true_col, pred_col, seq_col):   \n",
    "    # Check the agreement\n",
    "    predictions = []\n",
    "    true = []\n",
    "    missing = 0\n",
    "    for seq_label, res_sq, res_pred, seq in df[[id_col, true_col, pred_col, seq_col]].values:\n",
    "        res_sq = res_sq.split('|')\n",
    "        if not res_pred or not isinstance(res_pred, str):\n",
    "            res_pred = ''\n",
    "        res_pred = res_pred.split('|')\n",
    "        if len(res_pred) > 0:\n",
    "            try:\n",
    "                chosen_res_seq = [int(i) for i in res_pred]\n",
    "            except:\n",
    "                chosen_res_seq = []\n",
    "                missing += 1\n",
    "        res_sq = [int(i) for i in res_sq]\n",
    "        for pos in range(0, len(seq)):\n",
    "            if pos in res_sq:\n",
    "                true.append(1)\n",
    "            else:\n",
    "                true.append(0)\n",
    "            if pos in chosen_res_seq:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(true, predictions)\n",
    "    return precision[1], recall[1], f1[1], support[1]\n",
    "\n",
    "\n",
    "def calculate_stats_uncertainty(df, id_col, true_col, pred_col, seq_col):   \n",
    "    # Check the agreement:\n",
    "    rows = []\n",
    "    for seq_label, res_sq, res_pred, seq, mean_prob, alea, var in df[[id_col, true_col, pred_col, seq_col, 'mean_prob', 'entropy', 'variance']].values:\n",
    "        if not res_sq:\n",
    "            missing += 1\n",
    "        else:\n",
    "            res_sq = res_sq.split('|')\n",
    "            res_sq = [int(i) for i in res_sq]\n",
    "            for pos in range(0, len(seq)):\n",
    "                if pos in res_sq:\n",
    "                    rows.append([seq_label, pos, seq[pos], 1, mean_prob[pos], alea[pos], var[pos]])\n",
    "                else:\n",
    "                    rows.append([seq_label, pos, seq[pos], 0, mean_prob[pos], alea[pos], var[pos]])\n",
    "\n",
    "    return pd.DataFrame(rows, columns=['Entry', 'Position', 'Residue', 'True Catalytic', 'Mean Prob', 'Entropy', 'Variance'])\n",
    "\n",
    "\n",
    "def annotate_residue_from_uniprot(df):\n",
    "    # Organise the active sites of these guys to be better\n",
    "    active_sites = []\n",
    "    active_site_residue_counts = []\n",
    "    x = 0\n",
    "    for act_site in df['Active site'].values:\n",
    "        sites = []\n",
    "        if isinstance(act_site, str):\n",
    "            act_site = act_site.replace(\" \", '')\n",
    "            for act in act_site.split('ACT_SITE'):\n",
    "                try:\n",
    "                    sites.append(int(act.split(';')[0].replace(\" \", '')) - 1) # Need to subtract 1 to make it fit with the fact that python is 0 encoded lol\n",
    "                except:\n",
    "                    x = 1\n",
    "        if len(sites) != 0:\n",
    "            active_sites.append('|'.join([str(s) for s in sites]))\n",
    "            active_site_residue_counts.append(len(sites))\n",
    "        else:\n",
    "            active_sites.append('None')\n",
    "            active_site_residue_counts.append(0)\n",
    "    df['UniProtResidue'] = active_sites\n",
    "    df['active_site_residue_counts'] = active_site_residue_counts\n",
    "    return df\n",
    "\n",
    "\n",
    "swissprot = annotate_residue_from_uniprot(swissprot)\n",
    "swissprot = swissprot[swissprot['active_site_residue_counts'] > 0]\n",
    "training_ids = set(pd.read_csv('../manuscript/data/AEGAN_real_training_set.txt', header=None)[0].values)\n",
    "training_df = swissprot[swissprot['Entry'].isin(training_ids)]\n",
    "training_df['Residue'] = training_df['UniProtResidue'].values\n",
    "\n",
    "training_df.to_csv('data/AEGAN_swissprot_training.csv', index=False)\n",
    "u.dp(['Number of AEGAN training set:', len(training_df)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a8cbd-0984-4fdf-9b28-52e455012ba3",
   "metadata": {},
   "source": [
    "# For each of the families do the plot of the best range and then also calculate for the cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4532dbd-96db-4b2e-9d8b-a9fb0ca3cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tPC\tPrecision: 0.8571428571428571\tRecall: 0.8484848484848485\tF1: 0.8527918781725888\tSupport: 99\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tPC\tPrecision: 0.9361702127659575\tRecall: 0.8888888888888888\tF1: 0.9119170984455959\tSupport: 99\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tPC\tPrecision: 0.9361702127659575\tRecall: 0.8888888888888888\tF1: 0.9119170984455959\tSupport: 99\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tNN\tPrecision: 0.8208955223880597\tRecall: 0.8505154639175257\tF1: 0.8354430379746836\tSupport: 194\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tNN\tPrecision: 0.9553072625698324\tRecall: 0.8814432989690721\tF1: 0.9168900804289545\tSupport: 194\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tNN\tPrecision: 0.9510869565217391\tRecall: 0.9020618556701031\tF1: 0.9259259259259259\tSupport: 194\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tEF_superfamily\tPrecision: 0.8565217391304348\tRecall: 0.8995433789954338\tF1: 0.8775055679287305\tSupport: 219\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tEF_superfamily\tPrecision: 0.9603960396039604\tRecall: 0.8858447488584474\tF1: 0.9216152019002376\tSupport: 219\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tEF_superfamily\tPrecision: 0.9398148148148148\tRecall: 0.9269406392694064\tF1: 0.9333333333333332\tSupport: 219\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tEF_fold\tPrecision: 0.847953216374269\tRecall: 0.8787878787878788\tF1: 0.863095238095238\tSupport: 165\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tEF_fold\tPrecision: 0.9741935483870968\tRecall: 0.9151515151515152\tF1: 0.9437500000000001\tSupport: 165\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tEF_fold\tPrecision: 0.9627329192546584\tRecall: 0.9393939393939394\tF1: 0.9509202453987731\tSupport: 165\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tEF_family\tPrecision: 0.8204488778054863\tRecall: 0.8915989159891599\tF1: 0.8545454545454545\tSupport: 369\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tEF_family\tPrecision: 0.9378698224852071\tRecall: 0.8590785907859079\tF1: 0.8967468175388967\tSupport: 369\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tEF_family\tPrecision: 0.9346590909090909\tRecall: 0.8915989159891599\tF1: 0.9126213592233009\tSupport: 369\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[91mSquidly:\t3B\tHA_superfamily\tPrecision: 0.7986111111111112\tRecall: 0.8363636363636363\tF1: 0.8170515097690941\tSupport: 275\t\u001b[0m\n",
      "\u001b[91m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[93mBLAST\t3B\tHA_superfamily\tPrecision: 0.9446640316205533\tRecall: 0.8690909090909091\tF1: 0.9053030303030304\tSupport: 275\t\u001b[0m\n",
      "\u001b[93m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[94mSquidly + BLAST\t3B\tHA_superfamily\tPrecision: 0.9283018867924528\tRecall: 0.8945454545454545\tF1: 0.9111111111111111\tSupport: 275\t\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = ['PC',\n",
    "         'NN',\n",
    "         'EF_superfamily',\n",
    "         'EF_fold',\n",
    "         'EF_family',\n",
    "         'HA_superfamily'] \n",
    "\n",
    "rows = []\n",
    "for model in ['3B']:\n",
    "    for family in files:\n",
    "        # First join each of the data frames from the individual runs then compute the uncertainties \n",
    "        squidly_ensemble = pd.read_pickle(f'output/families_{model}/{family}/squidly_squidly.pkl')\n",
    "        if family != 'HA_superfamily': # Already fine\n",
    "            squidly_ensemble['label'] = [c[2:8] for c in squidly_ensemble['label'].values] # Need to only keep the uniprot IDs\n",
    "        squidly_ensemble.set_index('label', inplace=True)\n",
    "        \n",
    "        test_ids = set(pd.read_csv(f'{data_dir}/{family}/{family}.txt', header=None)[0].values)\n",
    "        true_df = swissprot[swissprot['Entry'].isin(test_ids)]\n",
    "        true_df.set_index('Entry', inplace=True)\n",
    "        true_df = true_df.join(squidly_ensemble, how='left', rsuffix='_')\n",
    "        true_df['label'] = true_df.index \n",
    "\n",
    "        precision, recall, f1, support = calculate_stats(true_df, 'label', 'UniProtResidue', 'Squidly_Ensemble_Residues', 'Sequence')\n",
    "        u.err_p(['Squidly:', model, family, f'Precision: {precision}', f'Recall: {recall}', f'F1: {f1}', f'Support: {support}'])\n",
    "\n",
    "        # Also print out the BLAST + squidly results\n",
    "        true_df = swissprot[swissprot['Entry'].isin(test_ids)]\n",
    "        true_df.set_index('Entry', inplace=True)\n",
    "        squidly_blast = pd.read_csv(f'output/families_{model}/{family}/squidly_blast.csv')\n",
    "        if family != 'HA_superfamily': # Already fine\n",
    "            squidly_blast['label'] = [c[2:8] for c in squidly_blast['From'].values] # Need to only keep the uniprot IDs\n",
    "        else:\n",
    "            squidly_blast['label'] = squidly_blast['From'].values\n",
    "        squidly_blast.set_index('label', inplace=True)\n",
    "        true_df = true_df.join(squidly_blast, how='left', rsuffix='_')\n",
    "        true_df['label'] = true_df.index\n",
    "        \n",
    "        precision, recall, f1, support = calculate_stats(true_df, 'label', 'UniProtResidue', 'BLAST_residues', 'Sequence')\n",
    "\n",
    "        u.warn_p(['BLAST', model, family, f'Precision: {precision}', f'Recall: {recall}', f'F1: {f1}', f'Support: {support}'])\n",
    "\n",
    "        # Also print out the BLAST + squidly results\n",
    "        true_df = swissprot[swissprot['Entry'].isin(test_ids)]\n",
    "        true_df.set_index('Entry', inplace=True)\n",
    "        squidly_blast_ensemble = pd.read_csv(f'output/families_{model}/{family}/squidly_ensemble.csv')\n",
    "        if family != 'HA_superfamily': # Already fine\n",
    "            squidly_blast_ensemble['label'] = [c[2:8] for c in squidly_blast_ensemble['id'].values] # Need to only keep the uniprot IDs\n",
    "        else:\n",
    "            squidly_blast_ensemble['label'] = squidly_blast_ensemble['id'].values\n",
    "        squidly_blast_ensemble.set_index('label', inplace=True)\n",
    "        true_df = true_df.join(squidly_blast_ensemble, how='left', rsuffix='_')\n",
    "        true_df['label'] = true_df.index\n",
    "        \n",
    "        precision, recall, f1, support = calculate_stats(true_df, 'label', 'UniProtResidue', 'residues', 'Sequence')\n",
    "\n",
    "        u.dp(['Squidly + BLAST', model, family, f'Precision: {precision}', f'Recall: {recall}', f'F1: {f1}', f'Support: {support}'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95de8b-73b9-4f55-b70e-83c202d2586c",
   "metadata": {},
   "source": [
    "# Make the plots as in the previous version of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bfd05-43a4-4455-ad67-bb16c98c5caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
